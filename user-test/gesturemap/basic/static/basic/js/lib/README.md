Gesture UI Development User Test
================================

Docs and Tutorials
------------------

In order to recreate a context similar to real-world application development, we provide you with two libraries,
one for managing the user's input and one for managing the application graphics. The graphics library provides UI 
components for managing the UI of the case study.
The input library provides a simplified implementation of the three approaches for recognizing the same gestures, 
which we are going to evaluate in this test.

As usually happens in modern software development, your role is to compose the capabilities of these libraries for 
creating a new application. We provide you with both a detailed API documentation, accessible through the side-panel
of this page, and with a set of tutorials on how to get started with each component. You are requested to give a brief
look at them in order to understand the role of each component in the target application. You can go back and read
the available documentation at any moment during the development. 

The tutorials are the following:
1. Graphics library
    1. Managing the grid map
    2. Using the line feedback
    3. Using the Octopocus feedback
2. Input library
    1. Registering strokes
    2. Recognizing gestures with Finite State Machines
    3. Recognizing gestures with Machine Learning
    4. Recognizing gestures with Deictic

